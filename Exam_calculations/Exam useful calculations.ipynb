{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Few calculations for the exam'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'M'}, {'D'}, {'Y'}, {'B', 'Y'}, {'C'}, {'B'}]\n",
      "[]\n",
      "[[{'B'}, {'Y'}, 0.75], [{'Y'}, {'B'}, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "''' install fpgrowth_py using: pip install fpgrowth_py'''\n",
    "from fpgrowth_py import fpgrowth\n",
    "\n",
    "def get_N_itemset(itemset, N):\n",
    "    output = [x for x in itemset if len(x)==N]\n",
    "    return output\n",
    "\n",
    "itemSetList = [['B', 'M', 'D'],\n",
    "                ['B', 'Y', 'M'],\n",
    "                ['M', 'D', 'C'],\n",
    "                ['B', 'Y', 'C'],\n",
    "                ['B', 'Y', 'D', 'C']]\n",
    "freqItemSet, rules = fpgrowth(itemSetList, minSupRatio=0.5, minConf=0.0)\n",
    "print(freqItemSet)\n",
    "print(get_N_itemset(freqItemSet, 3))\n",
    "\n",
    "print(rules) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for Yes_label\t= 4\n",
      "Count for No_label\t= 5\n",
      "Size of S\t= 9\n",
      "Entropy of S = 0.991\n",
      "\n",
      "\t\tValues for a1\n",
      "Count for T Yes_label\t= 3\n",
      "Count for T No_label\t= 1\n",
      "Size of S_T\t= 4\n",
      "\tEntropy of S_T = 0.811\n",
      "\n",
      "Count for F Yes_label\t= 1\n",
      "Count for F No_label\t= 4\n",
      "Size of S_F\t= 5\n",
      "\tEntropy of S_F = 0.722\n",
      "\n",
      "\t\tFinal Gain for a1 = 0.229\n",
      "\n",
      "\n",
      "\t\tValues for a2\n",
      "Count for T Yes_label\t= 2\n",
      "Count for T No_label\t= 3\n",
      "Size of S_T\t= 5\n",
      "\tEntropy of S_T = 0.971\n",
      "\n",
      "Count for F Yes_label\t= 2\n",
      "Count for F No_label\t= 2\n",
      "Size of S_F\t= 4\n",
      "\tEntropy of S_F = 1.0\n",
      "\n",
      "\t\tFinal Gain for a2 = 0.007\n",
      "\n",
      "\n",
      "\t\tValues for a3\n",
      "Count for L Yes_label\t= 1\n",
      "Count for L No_label\t= 0\n",
      "Size of S_L\t= 1\n",
      "\tEntropy of S_L = -0.0\n",
      "\n",
      "Count for H Yes_label\t= 2\n",
      "Count for H No_label\t= 2\n",
      "Size of S_H\t= 4\n",
      "\tEntropy of S_H = 1.0\n",
      "\n",
      "Count for M Yes_label\t= 1\n",
      "Count for M No_label\t= 3\n",
      "Size of S_M\t= 4\n",
      "\tEntropy of S_M = 0.811\n",
      "\n",
      "\t\tFinal Gain for a3 = 0.186\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''2008 Exam Q6 part b)'''\n",
    "''' DECISION TREE ID3 - INFORMATION GAIN '''\n",
    "'''Choose the attribute with highest gain'''\n",
    "import pandas as pd\n",
    "from math import log2\n",
    "\n",
    "IG_df = pd.read_csv(\"2008_exam_Q6.csv\", index_col=0)\n",
    "IG_df.columns = [*IG_df.columns[:-1], 'Label']\n",
    "\n",
    "count_samples_df = IG_df.apply(lambda x : True if x[\"Label\"]==\"Y\" else False, axis = 1)\n",
    "positive_samples = len(count_samples_df[count_samples_df == True].index)\n",
    "negative_samples = len(count_samples_df[count_samples_df == False].index)\n",
    "\n",
    "# S = [# positive samples, # negative samples]\n",
    "S = [positive_samples,negative_samples] \n",
    "size_S = S[0]+S[1]\n",
    "print(f'Count for Yes_label\\t= {positive_samples}')\n",
    "print(f'Count for No_label\\t= {negative_samples}')\n",
    "print(f'Size of S\\t= {size_S}')\n",
    "\n",
    "''' \n",
    "Gain(S, attribute) = Entropy(S) - SUM ( |Sv|/|S| )*Entropy(Sv)\n",
    "'''\n",
    "# ENTROPY of S\n",
    "if S[0]!=0 and S[1]!=0:\n",
    "    Entropy_S = -(S[0]/size_S)*log2(S[0]/size_S)-(S[1]/size_S)*log2(S[1]/size_S)\n",
    "elif S[0]!=0 and S[1]==0:\n",
    "    Entropy_S = -(S[0]/size_S)*log2(S[0]/size_S)\n",
    "else: \n",
    "    Entropy_S = -(S[1]/size_S)*log2(S[1]/size_S)\n",
    "    \n",
    "print(f'Entropy of S = {round(Entropy_S,3)}\\n')\n",
    "\n",
    "Gain = Entropy_S\n",
    "for column in IG_df.columns:\n",
    "    if column!= \"Label\":\n",
    "        Gain = Entropy_S\n",
    "        print(f'\\t\\tValues for {column}')\n",
    "        unique_values = IG_df[column].unique()\n",
    "\n",
    "        for value in unique_values:\n",
    "            V_yes_df = IG_df.apply(lambda x: True if x[\"Label\"]==\"Y\" and x[column]==value else False, axis = 1)\n",
    "            V_yes = len(V_yes_df[V_yes_df == True].index)\n",
    "            V_no_df = IG_df.apply(lambda x: True if x[\"Label\"]==\"N\" and x[column]==value else False, axis = 1)\n",
    "            V_no = len(V_no_df[V_no_df == True].index)\n",
    "            \n",
    "            S_V = [V_yes,V_no]\n",
    "            size_V = (V_yes+V_no)\n",
    "            print(f'Count for {value} Yes_label\\t= {V_yes}')\n",
    "            print(f'Count for {value} No_label\\t= {V_no}')\n",
    "            print(f'Size of S_{value}\\t= {size_V}')\n",
    "            \n",
    "            # ENTROPY of Variables\n",
    "            if S_V[0]!=0 and S_V[1]!=0:\n",
    "                Entropy_V = -(S_V[0]/size_V)*log2(S_V[0]/size_V)-(S_V[1]/size_V)*log2(S_V[1]/size_V)\n",
    "            elif S_V[0]!=0 and S_V[1]==0:\n",
    "                Entropy_V = -(S_V[0]/size_V)*log2(S_V[0]/size_V)\n",
    "            else: \n",
    "                Entropy_V = -(S_V[1]/size_V)*log2(S_V[1]/size_V) \n",
    "            \n",
    "            print(f'\\tEntropy of S_{value} = {round(Entropy_V,3)}\\n')\n",
    "            \n",
    "            Gain = Gain - (size_V/size_S)*Entropy_V\n",
    "            \n",
    "        print(f'\\t\\tFinal Gain for {column} = {round(Gain,3)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for Yes_label\t= 3\n",
      "Count for No_label\t= 1\n",
      "Size of S\t= 4\n",
      "Entropy of S = 0.811\n",
      "\n",
      "\t\tValues for a2\n",
      "Count for T Yes_label\t= 2\n",
      "Count for T No_label\t= 0\n",
      "Size of S_T\t= 2\n",
      "\tEntropy of S_T = -0.0\n",
      "\n",
      "Count for F Yes_label\t= 1\n",
      "Count for F No_label\t= 1\n",
      "Size of S_F\t= 2\n",
      "\tEntropy of S_F = 1.0\n",
      "\n",
      "\t\tFinal Gain for a2 = 0.311\n",
      "\n",
      "\n",
      "\t\tValues for a3\n",
      "Count for L Yes_label\t= 1\n",
      "Count for L No_label\t= 0\n",
      "Size of S_L\t= 1\n",
      "\tEntropy of S_L = -0.0\n",
      "\n",
      "Count for H Yes_label\t= 2\n",
      "Count for H No_label\t= 0\n",
      "Size of S_H\t= 2\n",
      "\tEntropy of S_H = -0.0\n",
      "\n",
      "Count for M Yes_label\t= 0\n",
      "Count for M No_label\t= 1\n",
      "Size of S_M\t= 1\n",
      "\tEntropy of S_M = -0.0\n",
      "\n",
      "\t\tFinal Gain for a3 = 0.811\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''2008 Exam Q6 part b)  Continuation...   '''\n",
    "''' DECISION TREE ID3 - INFORMATION GAIN '''\n",
    "''' \n",
    "Chose a1 as splitting attribute, \n",
    "eliminate column a1 from csv file and create 2 csv files:\n",
    "one for rows where a1 = true, new file1 = 2008_exam_Q6_a11.csv\n",
    "one for rows where a1 = false, new file2 = 2008_exam_Q6_a12.csv\n",
    "'''\n",
    "import pandas as pd\n",
    "from math import log2\n",
    "\n",
    "IG_df = pd.read_csv(\"2008_exam_Q6_a11.csv\", index_col=0)\n",
    "IG_df.columns = [*IG_df.columns[:-1], 'Label']\n",
    "\n",
    "count_samples_df = IG_df.apply(lambda x : True if x[\"Label\"]==\"Y\" else False, axis = 1)\n",
    "positive_samples = len(count_samples_df[count_samples_df == True].index)\n",
    "negative_samples = len(count_samples_df[count_samples_df == False].index)\n",
    "\n",
    "# S = [# positive samples, # negative samples]\n",
    "S = [positive_samples,negative_samples] \n",
    "size_S = S[0]+S[1]\n",
    "print(f'Count for Yes_label\\t= {positive_samples}')\n",
    "print(f'Count for No_label\\t= {negative_samples}')\n",
    "print(f'Size of S\\t= {size_S}')\n",
    "\n",
    "''' \n",
    "Gain(S, attribute) = Entropy(S) - SUM ( |Sv|/|S| )*Entropy(Sv)\n",
    "'''\n",
    "# ENTROPY of S\n",
    "if S[0]!=0 and S[1]!=0:\n",
    "    Entropy_S = -(S[0]/size_S)*log2(S[0]/size_S)-(S[1]/size_S)*log2(S[1]/size_S)\n",
    "elif S[0]!=0 and S[1]==0:\n",
    "    Entropy_S = -(S[0]/size_S)*log2(S[0]/size_S)\n",
    "else: \n",
    "    Entropy_S = -(S[1]/size_S)*log2(S[1]/size_S)\n",
    "    \n",
    "print(f'Entropy of S = {round(Entropy_S,3)}\\n')\n",
    "\n",
    "Gain = Entropy_S\n",
    "for column in IG_df.columns:\n",
    "    if column!= \"Label\":\n",
    "        Gain = Entropy_S\n",
    "        print(f'\\t\\tValues for {column}')\n",
    "        unique_values = IG_df[column].unique()\n",
    "\n",
    "        for value in unique_values:\n",
    "            V_yes_df = IG_df.apply(lambda x: True if x[\"Label\"]==\"Y\" and x[column]==value else False, axis = 1)\n",
    "            V_yes = len(V_yes_df[V_yes_df == True].index)\n",
    "            V_no_df = IG_df.apply(lambda x: True if x[\"Label\"]==\"N\" and x[column]==value else False, axis = 1)\n",
    "            V_no = len(V_no_df[V_no_df == True].index)\n",
    "            \n",
    "            S_V = [V_yes,V_no]\n",
    "            size_V = (V_yes+V_no)\n",
    "            print(f'Count for {value} Yes_label\\t= {V_yes}')\n",
    "            print(f'Count for {value} No_label\\t= {V_no}')\n",
    "            print(f'Size of S_{value}\\t= {size_V}')\n",
    "            \n",
    "            # ENTROPY of Variables\n",
    "            if S_V[0]!=0 and S_V[1]!=0:\n",
    "                Entropy_V = -(S_V[0]/size_V)*log2(S_V[0]/size_V)-(S_V[1]/size_V)*log2(S_V[1]/size_V)\n",
    "            elif S_V[0]!=0 and S_V[1]==0:\n",
    "                Entropy_V = -(S_V[0]/size_V)*log2(S_V[0]/size_V)\n",
    "            else: \n",
    "                Entropy_V = -(S_V[1]/size_V)*log2(S_V[1]/size_V) \n",
    "            \n",
    "            print(f'\\tEntropy of S_{value} = {round(Entropy_V,3)}\\n')\n",
    "            \n",
    "            Gain = Gain - (size_V/size_S)*Entropy_V\n",
    "            \n",
    "        print(f'\\t\\tFinal Gain for {column} = {round(Gain,3)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for Yes_Class\t= 0.444\n",
      "Probabilities for No_Class\t= 0.556\n",
      "\n",
      "\tProbabilities for a1:\n",
      "P(T| Yes_Class)\t= 3/4\t= 0.75 \n",
      "P(T| No_Class)\t= 1/5\t= 0.2\n",
      "\n",
      "P(F| Yes_Class)\t= 1/4\t= 0.25 \n",
      "P(F| No_Class)\t= 4/5\t= 0.8\n",
      "\n",
      "\n",
      "\tProbabilities for a2:\n",
      "P(T| Yes_Class)\t= 2/4\t= 0.5 \n",
      "P(T| No_Class)\t= 3/5\t= 0.6\n",
      "\n",
      "P(F| Yes_Class)\t= 2/4\t= 0.5 \n",
      "P(F| No_Class)\t= 2/5\t= 0.4\n",
      "\n",
      "\n",
      "\tProbabilities for a3:\n",
      "P(L| Yes_Class)\t= 1/4\t= 0.25 \n",
      "P(L| No_Class)\t= 0/5\t= 0.0\n",
      "\n",
      "P(H| Yes_Class)\t= 2/4\t= 0.5 \n",
      "P(H| No_Class)\t= 2/5\t= 0.4\n",
      "\n",
      "P(M| Yes_Class)\t= 1/4\t= 0.25 \n",
      "P(M| No_Class)\t= 3/5\t= 0.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''2008 Exam Q6 part c)'''\n",
    "''' Naive Bayes Classifier'''\n",
    "''' Choose the probabilities you are asked to classify'''\n",
    "''' Then multiply them'''\n",
    "import pandas as pd\n",
    "\n",
    "NB_df = pd.read_csv(\"2008_exam_Q6.csv\", index_col=0)\n",
    "NB_df.columns = [*NB_df.columns[:-1], 'Class']\n",
    "\n",
    "samples_df = NB_df.apply(lambda x : True if x[\"Class\"]==\"Y\" else False, axis = 1)\n",
    "positive_samples = len(samples_df[samples_df == True].index)\n",
    "negative_samples = len(samples_df[samples_df == False].index)\n",
    "print(f'Probabilities for Yes_Class\\t= {round(positive_samples/(positive_samples+negative_samples),3)}')\n",
    "print(f'Probabilities for No_Class\\t= {round(negative_samples/(positive_samples+negative_samples),3)}')\n",
    "for column in NB_df.columns:\n",
    "    if column!= \"Class\":\n",
    "        unique_values = NB_df[column].unique()\n",
    "        print(f'\\n\\tProbabilities for {column}:')\n",
    "        for value in unique_values:\n",
    "            V_T_df = NB_df.apply(lambda x: True if x[\"Class\"]==\"Y\" and x[column]==value else False, axis = 1)\n",
    "            numTrue = len(V_T_df[V_T_df == True].index)\n",
    "            denomTrue = positive_samples\n",
    "            V_True = round(numTrue / denomTrue,3)\n",
    "            V_F_df = NB_df.apply(lambda x: True if x[\"Class\"]==\"N\" and x[column]==value else False, axis = 1)\n",
    "            numFalse = len(V_F_df[V_F_df == True].index)\n",
    "            denomFalse = negative_samples\n",
    "            V_False = round(numFalse / denomFalse,3)\n",
    "            print(f'P({value}| Yes_Class)\\t= {numTrue}/{denomTrue}\\t= {V_True} ')\n",
    "            print(f'P({value}| No_Class)\\t= {numFalse}/{denomFalse}\\t= {V_False}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.042\n",
      "0.027\n"
     ]
    }
   ],
   "source": [
    "''' Choose highest probability'''\n",
    "print(round(0.444*0.75*0.5*0.25,3))\n",
    "print(round(0.556*0.6*0.4*0.2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   a_1  a_2  a_3  Label\n",
      "0    1    1    0      1\n",
      "1    1    1    2      1\n",
      "2    1    0    1      0\n",
      "3    0    0    1      1\n",
      "4    0    1    2      0\n",
      "5    0    1    1      0\n",
      "6    0    0    2      0\n",
      "7    1    0    2      1\n",
      "8    0    1    1      0\n",
      "a_1   0.344\n",
      "a_2   0.489\n",
      "a_3   0.344\n"
     ]
    }
   ],
   "source": [
    "''' DECISION TREE CART - GINI INDEX '''\n",
    "''' GINI Index calculation for binary variables : {yes, no} or {true, false} etc...'''\n",
    "import pandas as pd\n",
    "\n",
    "''' Male=1, Female=0  //  Yes=1, No=0'''\n",
    "data = {\"a_1\":[1,1,1,0,0,0,0,1,0],\"a_2\":[1,1,0,0,1,1,0,0,1],\"a_3\":[0,2,1,1,2,1,2,2,1],\n",
    "        \"Label\":[1,1,0,1,0,0,0,1,0]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "label_df = df[\"Label\"].copy(deep=True)\n",
    "print(df)\n",
    "def get_gini(df, col):  \n",
    "    df_num_yes = df.apply(lambda x : True\n",
    "            if x[col]==1 and x[\"Label\"]==1 else False, axis = 1)\n",
    "    # Count number of True in the series\n",
    "    num1_yes = len(df_num_yes[df_num_yes == True].index)\n",
    "    \n",
    "    df_num_no = df.apply(lambda x : True\n",
    "        if x[col]==0 and x[\"Label\"]==1 else False, axis = 1)\n",
    "    # Count number of True in the series\n",
    "    num1_no = len(df_num_no[df_num_no == True].index)\n",
    "    \n",
    "    df_denom = df.apply(lambda x : True\n",
    "        if x[col]==1 else False, axis = 1)\n",
    "    \n",
    "    # Count number of True in the series\n",
    "    denom_yes = len(df_denom[df_denom == True].index)\n",
    "    denom_no = len(df_denom[df_denom == False].index)\n",
    "    \n",
    "    num2_yes = denom_yes - num1_yes\n",
    "    num2_no = denom_no - num1_no\n",
    "    \n",
    "    gini_1 = 1 - (num1_yes/denom_yes)**2 - (num2_yes/denom_yes)**2\n",
    "    gini_2 = 1 - (num1_no/denom_no)**2 - (num2_no/denom_no)**2\n",
    "    \n",
    "    gini = (denom_yes/(denom_yes+denom_no))*gini_1 + (denom_no/(denom_yes+denom_no))*gini_2\n",
    "    \n",
    "    return round(gini,3)\n",
    "\n",
    "for col in df.columns:\n",
    "    if col != \"Label\":\n",
    "        gini = get_gini(df, col)\n",
    "        print(col, \" \", gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.9750566893424"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' FINAL MARK '''\n",
    "lab1 = 100\n",
    "lab2 = 100\n",
    "lab3 = 100\n",
    "labs = ((lab1+lab2+lab3)/300)*25\n",
    "\n",
    "ass = 0.75*25\n",
    "proj_points = 45 + 0 + 8    # Part1 + Part2 + Report\n",
    "proj = proj_points*0.5\n",
    "exam = 40\n",
    "final = 2*(labs+ass+proj)*exam/(labs+ass+proj+exam)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for Yes_Class\t= 0.643\n",
      "Probabilities for No_Class\t= 0.357\n",
      "\n",
      "\tProbabilities for Outlook:\n",
      "P(Sunny| Yes_Class)\t= 2/9\t= 0.222 \n",
      "P(Sunny| No_Class)\t= 3/5\t= 0.6\n",
      "\n",
      "P(Overcast| Yes_Class)\t= 4/9\t= 0.444 \n",
      "P(Overcast| No_Class)\t= 0/5\t= 0.0\n",
      "\n",
      "P(Rain| Yes_Class)\t= 3/9\t= 0.333 \n",
      "P(Rain| No_Class)\t= 2/5\t= 0.4\n",
      "\n",
      "\n",
      "\tProbabilities for Temperature:\n",
      "P(Hot| Yes_Class)\t= 2/9\t= 0.222 \n",
      "P(Hot| No_Class)\t= 2/5\t= 0.4\n",
      "\n",
      "P(Mild| Yes_Class)\t= 4/9\t= 0.444 \n",
      "P(Mild| No_Class)\t= 2/5\t= 0.4\n",
      "\n",
      "P(Cool| Yes_Class)\t= 3/9\t= 0.333 \n",
      "P(Cool| No_Class)\t= 1/5\t= 0.2\n",
      "\n",
      "\n",
      "\tProbabilities for Humidity:\n",
      "P(High| Yes_Class)\t= 3/9\t= 0.333 \n",
      "P(High| No_Class)\t= 4/5\t= 0.8\n",
      "\n",
      "P(Normal| Yes_Class)\t= 6/9\t= 0.667 \n",
      "P(Normal| No_Class)\t= 1/5\t= 0.2\n",
      "\n",
      "\n",
      "\tProbabilities for Wind:\n",
      "P(Weak| Yes_Class)\t= 6/9\t= 0.667 \n",
      "P(Weak| No_Class)\t= 2/5\t= 0.4\n",
      "\n",
      "P(Strong| Yes_Class)\t= 3/9\t= 0.333 \n",
      "P(Strong| No_Class)\t= 3/5\t= 0.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' Naive Bayes Classifier'''\n",
    "''' Random example'''\n",
    "import pandas as pd\n",
    "\n",
    "NB_df = pd.read_csv(\"decision_tree.csv\", index_col=0)\n",
    "NB_df.columns = [*NB_df.columns[:-1], 'Class']\n",
    "\n",
    "samples_df = NB_df.apply(lambda x : True if x[\"Class\"]==\"Yes\" else False, axis = 1)\n",
    "positive_samples = len(samples_df[samples_df == True].index)\n",
    "negative_samples = len(samples_df[samples_df == False].index)\n",
    "print(f'Probabilities for Yes_Class\\t= {round(positive_samples/(positive_samples+negative_samples),3)}')\n",
    "print(f'Probabilities for No_Class\\t= {round(negative_samples/(positive_samples+negative_samples),3)}')\n",
    "for column in NB_df.columns:\n",
    "    if column!= \"Class\":\n",
    "        unique_values = NB_df[column].unique()\n",
    "        print(f'\\n\\tProbabilities for {column}:')\n",
    "        for value in unique_values:\n",
    "            V_T_df = NB_df.apply(lambda x: True if x[\"Class\"]==\"Yes\" and x[column]==value else False, axis = 1)\n",
    "            numTrue = len(V_T_df[V_T_df == True].index)\n",
    "            denomTrue = positive_samples\n",
    "            V_True = round(numTrue / denomTrue,3)\n",
    "            V_F_df = NB_df.apply(lambda x: True if x[\"Class\"]==\"No\" and x[column]==value else False, axis = 1)\n",
    "            numFalse = len(V_F_df[V_F_df == True].index)\n",
    "            denomFalse = negative_samples\n",
    "            V_False = round(numFalse / denomFalse,3)\n",
    "            print(f'P({value}| Yes_Class)\\t= {numTrue}/{denomTrue}\\t= {V_True} ')\n",
    "            print(f'P({value}| No_Class)\\t= {numFalse}/{denomFalse}\\t= {V_False}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count for Yes_label\t= 9\n",
      "Count for No_label\t= 5\n",
      "Size of S\t= 14\n",
      "Entropy of S = 0.94\n",
      "\n",
      "\t\tValues for Outlook\n",
      "Count for Sunny Yes_label\t= 2\n",
      "Count for Sunny No_label\t= 3\n",
      "Size of S_Sunny\t= 5\n",
      "\tEntropy of S_Sunny = 0.971\n",
      "\n",
      "Count for Overcast Yes_label\t= 4\n",
      "Count for Overcast No_label\t= 0\n",
      "Size of S_Overcast\t= 4\n",
      "\tEntropy of S_Overcast = -0.0\n",
      "\n",
      "Count for Rain Yes_label\t= 3\n",
      "Count for Rain No_label\t= 2\n",
      "Size of S_Rain\t= 5\n",
      "\tEntropy of S_Rain = 0.971\n",
      "\n",
      "\t\tFinal Gain for Outlook = 0.247\n",
      "\n",
      "\n",
      "\t\tValues for Temperature\n",
      "Count for Hot Yes_label\t= 2\n",
      "Count for Hot No_label\t= 2\n",
      "Size of S_Hot\t= 4\n",
      "\tEntropy of S_Hot = 1.0\n",
      "\n",
      "Count for Mild Yes_label\t= 4\n",
      "Count for Mild No_label\t= 2\n",
      "Size of S_Mild\t= 6\n",
      "\tEntropy of S_Mild = 0.918\n",
      "\n",
      "Count for Cool Yes_label\t= 3\n",
      "Count for Cool No_label\t= 1\n",
      "Size of S_Cool\t= 4\n",
      "\tEntropy of S_Cool = 0.811\n",
      "\n",
      "\t\tFinal Gain for Temperature = 0.029\n",
      "\n",
      "\n",
      "\t\tValues for Humidity\n",
      "Count for High Yes_label\t= 3\n",
      "Count for High No_label\t= 4\n",
      "Size of S_High\t= 7\n",
      "\tEntropy of S_High = 0.985\n",
      "\n",
      "Count for Normal Yes_label\t= 6\n",
      "Count for Normal No_label\t= 1\n",
      "Size of S_Normal\t= 7\n",
      "\tEntropy of S_Normal = 0.592\n",
      "\n",
      "\t\tFinal Gain for Humidity = 0.152\n",
      "\n",
      "\n",
      "\t\tValues for Wind\n",
      "Count for Weak Yes_label\t= 6\n",
      "Count for Weak No_label\t= 2\n",
      "Size of S_Weak\t= 8\n",
      "\tEntropy of S_Weak = 0.811\n",
      "\n",
      "Count for Strong Yes_label\t= 3\n",
      "Count for Strong No_label\t= 3\n",
      "Size of S_Strong\t= 6\n",
      "\tEntropy of S_Strong = 1.0\n",
      "\n",
      "\t\tFinal Gain for Wind = 0.048\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' DECISION TREE ID3 - INFORMATION GAIN '''\n",
    "''' Entropy calculation for 3 possible variables of Outlook: {sunny, overcast, rain}'''\n",
    "import pandas as pd\n",
    "from math import log2\n",
    "\n",
    "IG_df = pd.read_csv(\"decision_tree.csv\", index_col=0)\n",
    "IG_df.columns = [*IG_df.columns[:-1], 'Label']\n",
    "\n",
    "count_samples_df = IG_df.apply(lambda x : True if x[\"Label\"]==\"Yes\" else False, axis = 1)\n",
    "positive_samples = len(count_samples_df[count_samples_df == True].index)\n",
    "negative_samples = len(count_samples_df[count_samples_df == False].index)\n",
    "\n",
    "# S = [# positive samples, # negative samples]\n",
    "S = [positive_samples,negative_samples] \n",
    "size_S = S[0]+S[1]\n",
    "print(f'Count for Yes_label\\t= {positive_samples}')\n",
    "print(f'Count for No_label\\t= {negative_samples}')\n",
    "print(f'Size of S\\t= {size_S}')\n",
    "\n",
    "''' \n",
    "Gain(S, attribute) = Entropy(S) - SUM ( |Sv|/|S| )*Entropy(Sv)\n",
    "'''\n",
    "# ENTROPY of S\n",
    "if S[0]!=0 and S[1]!=0:\n",
    "    Entropy_S = -(S[0]/size_S)*log2(S[0]/size_S)-(S[1]/size_S)*log2(S[1]/size_S)\n",
    "elif S[0]!=0 and S[1]==0:\n",
    "    Entropy_S = -(S[0]/size_S)*log2(S[0]/size_S)\n",
    "else: \n",
    "    Entropy_S = -(S[1]/size_S)*log2(S[1]/size_S)\n",
    "    \n",
    "print(f'Entropy of S = {round(Entropy_S,3)}\\n')\n",
    "\n",
    "Gain = Entropy_S\n",
    "for column in IG_df.columns:\n",
    "    if column!= \"Label\":\n",
    "        Gain = Entropy_S\n",
    "        print(f'\\t\\tValues for {column}')\n",
    "        unique_values = IG_df[column].unique()\n",
    "\n",
    "        for value in unique_values:\n",
    "            V_yes_df = IG_df.apply(lambda x: True if x[\"Label\"]==\"Yes\" and x[column]==value else False, axis = 1)\n",
    "            V_yes = len(V_yes_df[V_yes_df == True].index)\n",
    "            V_no_df = IG_df.apply(lambda x: True if x[\"Label\"]==\"No\" and x[column]==value else False, axis = 1)\n",
    "            V_no = len(V_no_df[V_no_df == True].index)\n",
    "            \n",
    "            S_V = [V_yes,V_no]\n",
    "            size_V = (V_yes+V_no)\n",
    "            print(f'Count for {value} Yes_label\\t= {V_yes}')\n",
    "            print(f'Count for {value} No_label\\t= {V_no}')\n",
    "            print(f'Size of S_{value}\\t= {size_V}')\n",
    "            \n",
    "            # ENTROPY of Variables\n",
    "            if S_V[0]!=0 and S_V[1]!=0:\n",
    "                Entropy_V = -(S_V[0]/size_V)*log2(S_V[0]/size_V)-(S_V[1]/size_V)*log2(S_V[1]/size_V)\n",
    "            elif S_V[0]!=0 and S_V[1]==0:\n",
    "                Entropy_V = -(S_V[0]/size_V)*log2(S_V[0]/size_V)\n",
    "            else: \n",
    "                Entropy_V = -(S_V[1]/size_V)*log2(S_V[1]/size_V) \n",
    "            \n",
    "            print(f'\\tEntropy of S_{value} = {round(Entropy_V,3)}\\n')\n",
    "            \n",
    "            Gain = Gain - (size_V/size_S)*Entropy_V\n",
    "            \n",
    "        print(f'\\t\\tFinal Gain for {column} = {round(Gain,3)}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
